{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f677e78",
   "metadata": {
    "id": "7f677e78"
   },
   "source": [
    "In this notebook, we will write a complete pipeline for **training a model to obtain node embeddings**.\n",
    "\n",
    "To begin, we will again work with the [Karate Club Network](https://en.wikipedia.org/wiki/Zachary%27s_karate_club). We will compute several statistics for this graph and then transform its structure into a PyTorch tensor.\n",
    "\n",
    "Next, we will implement a training algorithm for graphs: a model for obtaining node embeddings.\n",
    "\n",
    "We will also explore graph kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928758bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T21:13:29.002855Z",
     "start_time": "2022-09-14T21:13:28.886621Z"
    },
    "id": "928758bd"
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f896e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T21:13:50.309803Z",
     "start_time": "2022-09-14T21:13:50.211654Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "1f896e4d",
    "outputId": "baf7c9bf-e27c-4e59-e2b8-4e550c4f9177"
   },
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "\n",
    "# Visualize the graph\n",
    "nx.draw(G, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87804a72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T21:13:15.159190Z",
     "start_time": "2022-09-14T21:13:15.148766Z"
    },
    "id": "87804a72"
   },
   "source": [
    "**Average node degree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5481eafe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T21:22:50.972142Z",
     "start_time": "2022-09-14T21:22:50.957891Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5481eafe",
    "outputId": "e6dc0223-d131-44e3-ff36-421c42219c19"
   },
   "outputs": [],
   "source": [
    "def average_degree(num_edges, num_nodes):\n",
    "    # TODO: Implement this function that takes number of edges\n",
    "    # and number of nodes, and returns the average node degree of \n",
    "    # the graph. Round the result to nearest integer\n",
    "\n",
    "    avg_degree = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "\n",
    "    #########################################\n",
    "    \n",
    "    avg_degree = round(2 * num_edges / num_nodes)\n",
    "\n",
    "    return avg_degree\n",
    "\n",
    "num_edges = G.number_of_edges()\n",
    "num_nodes = G.number_of_nodes()\n",
    "avg_degree = average_degree(num_edges, num_nodes)\n",
    "print(\"Average degree of karate club network is {}\".format(avg_degree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b8edb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T22:54:38.205983Z",
     "start_time": "2022-09-14T22:54:38.190144Z"
    },
    "id": "51b8edb0"
   },
   "source": [
    "__Average clustering coefficient__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2167c00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2167c00",
    "outputId": "b49ba777-2b21-4e9a-b5d1-b9755a686ad5"
   },
   "outputs": [],
   "source": [
    "def average_clustering_coefficient(G):\n",
    "    # TODO: Implement this function that takes a nx.Graph\n",
    "    # and returns the average clustering coefficient. Round \n",
    "    # the result to 2 decimal places (for example 3.333 will\n",
    "    # be rounded to 3.33 and 3.7571 will be rounded to 3.76)\n",
    "\n",
    "    avg_cluster_coef = 0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    ## Note: \n",
    "    ## 1: Please use the appropriate NetworkX clustering function\n",
    "\n",
    "    avg_cluster_coef = nx.algorithms.approximation.clustering_coefficient.average_clustering(G)\n",
    "\n",
    "    return avg_cluster_coef, nx.algorithms.average_clustering(G)\n",
    "\n",
    "avg_cluster_coef = average_clustering_coefficient(G)\n",
    "print(\"Average clustering coefficient of karate club network is {}\".format(avg_cluster_coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b296bf96",
   "metadata": {
    "id": "b296bf96"
   },
   "source": [
    "__Ð¡loseness centrality__\n",
    "\n",
    "$c(v) = \\frac{1}{\\sum_{u \\neq v}\\text{shortest path length between } u \\text{ and } v}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a86f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "636a86f6",
    "outputId": "1e106bcb-5e54-4be2-c135-0bfe629498d6"
   },
   "outputs": [],
   "source": [
    "def closeness_centrality(G, node=5):\n",
    "    # TODO: Implement the function that calculates closeness centrality \n",
    "    # for a node in karate club network. G is the input karate club \n",
    "    # network and node is the node id in the graph. Please round the \n",
    "    # closeness centrality result to 2 decimal places.\n",
    "\n",
    "    closeness = 0\n",
    "\n",
    "    ## Note:\n",
    "    ## 1: You can use networkx closeness centrality function.\n",
    "    ## 2: Notice that networkx closeness centrality returns the normalized \n",
    "    ## closeness directly, which is different from the raw (unnormalized) \n",
    "    ## one that we learned in the lecture.\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    closeness = nx.centrality.closeness_centrality(G, node)\n",
    "\n",
    "    return closeness\n",
    "\n",
    "node = 5\n",
    "closeness = closeness_centrality(G, node=node)\n",
    "print(\"The node 5 has closeness centrality {}\".format(closeness))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-liberia",
   "metadata": {
    "id": "biblical-liberia"
   },
   "source": [
    "### Link prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-associate",
   "metadata": {
    "id": "linear-associate"
   },
   "source": [
    "__Jaccard coefficient__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-program",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T12:50:28.080879Z",
     "start_time": "2022-09-15T12:50:28.015822Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "lovely-program",
    "outputId": "9232837a-b27c-49a0-dc3c-c1e9c6e4d117"
   },
   "outputs": [],
   "source": [
    "G = nx.complete_graph(5)\n",
    "\n",
    "nx.draw(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-burns",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "subjective-burns",
    "outputId": "b59b9f1f-b510-42c5-91c7-5d550cb407a8"
   },
   "outputs": [],
   "source": [
    "preds = nx.jaccard_coefficient(G, [(0, 1), (2, 3)])\n",
    "for u, v, p in preds:\n",
    "     print('(%d, %d) -> %.8f' % (u, v, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-framework",
   "metadata": {
    "id": "broadband-framework"
   },
   "source": [
    "__Common neighbors__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-combination",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "transsexual-combination",
    "outputId": "eacc0dac-369a-4546-af44-9a44f5a6294c"
   },
   "outputs": [],
   "source": [
    "sorted(nx.common_neighbors(G, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-member",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T12:45:32.419466Z",
     "start_time": "2022-09-15T12:45:32.414907Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "medium-member",
    "outputId": "b2b48e2a-0601-4f26-8eb7-8d0084ef7042"
   },
   "outputs": [],
   "source": [
    "preds = nx.common_neighbor_centrality(G, [(0, 1), (2, 3)])\n",
    "for u, v, p in preds:\n",
    "    print(f\"({u}, {v}) -> {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-montgomery",
   "metadata": {
    "id": "brilliant-montgomery"
   },
   "source": [
    "__Adamic-Adar index__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-cheat",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T12:44:09.348948Z",
     "start_time": "2022-09-15T12:44:09.344265Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "seeing-cheat",
    "outputId": "2550be33-ee85-43a1-b894-413bc57cf357"
   },
   "outputs": [],
   "source": [
    "preds = nx.adamic_adar_index(G, [(0, 1), (2, 3)])\n",
    "for u, v, p in preds:\n",
    "    print('(%d, %d) -> %.8f' % (u, v, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92565898",
   "metadata": {
    "id": "92565898"
   },
   "source": [
    "## Converting the graph to a PyTorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a193f",
   "metadata": {
    "id": "ed4a193f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "G = nx.karate_club_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b917ab2",
   "metadata": {
    "id": "4b917ab2"
   },
   "source": [
    "### Tensors in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b970d99",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b970d99",
    "outputId": "bd680d7a-12b8-4b40-802f-3052cc535d90"
   },
   "outputs": [],
   "source": [
    "# Generate 3 x 4 tensor with all ones\n",
    "ones = torch.ones(3, 4)\n",
    "print(ones)\n",
    "\n",
    "# Generate 3 x 4 tensor with all zeros\n",
    "zeros = torch.zeros(3, 4)\n",
    "print(zeros)\n",
    "\n",
    "# Generate 3 x 4 tensor with random values on the interval [0, 1)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "print(random_tensor)\n",
    "\n",
    "# Get the shape of the tensor\n",
    "print(ones.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b596617c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b596617c",
    "outputId": "26868d77-a7ff-4cc1-e477-b265f62b79a2"
   },
   "outputs": [],
   "source": [
    "# Create a 3 x 4 tensor with all 32-bit floating point zeros\n",
    "zeros = torch.zeros(3, 4, dtype=torch.float32)\n",
    "print(zeros.dtype)\n",
    "\n",
    "# Change the tensor dtype to 64-bit integer\n",
    "zeros = zeros.type(torch.long)\n",
    "print(zeros.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7f6611",
   "metadata": {
    "id": "1a7f6611"
   },
   "source": [
    "Retrieve the list of graph edges and convert it into a `torch.LongTensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f537675",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9f537675",
    "outputId": "624ec858-5c2e-4290-dd89-645a2d0ac5b8"
   },
   "outputs": [],
   "source": [
    "def graph_to_edge_list(G):\n",
    "    # TODO: Implement the function that returns the edge list of\n",
    "    # an nx.Graph. The returned edge_list should be a list of tuples\n",
    "    # where each tuple is a tuple representing an edge connected \n",
    "    # by two nodes.\n",
    "\n",
    "    edge_list = list(G.edges())\n",
    "\n",
    "    ############# Your code here ############\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    return edge_list\n",
    "\n",
    "def edge_list_to_tensor(edge_list):\n",
    "    # TODO: Implement the function that transforms the edge_list to\n",
    "    # tensor. The input edge_list is a list of tuples and the resulting\n",
    "    # tensor should have the shape [2 x len(edge_list)].\n",
    "\n",
    "    edge_index = torch.tensor([])\n",
    "\n",
    "    ############# Your code here ############\n",
    "\n",
    "    #########################################\n",
    "\n",
    "\n",
    "    edge_index = torch.tensor(edge_list, dtype=torch.long).permute((1, 0))\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "pos_edge_list = graph_to_edge_list(G)\n",
    "pos_edge_index = edge_list_to_tensor(pos_edge_list)\n",
    "print(\"The pos_edge_index tensor has shape {}\".format(pos_edge_index.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1120aeaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-14T23:45:13.913833Z",
     "start_time": "2022-09-14T23:45:13.886907Z"
    },
    "id": "1120aeaf"
   },
   "source": [
    "Let's sample negative edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29395e53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29395e53",
    "outputId": "5dcb3127-d2fe-4b24-cc1b-85b51d5e005e"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def sample_negative_edges(G, num_neg_samples):\n",
    "    # TODO: Implement the function that returns a list of negative edges.\n",
    "    # The number of sampled negative edges is num_neg_samples. You do not\n",
    "    # need to consider the corner case when the number of possible negative edges\n",
    "    # is less than num_neg_samples. It should be ok as long as your implementation \n",
    "    # works on the karate club network. In this implementation, self loops should \n",
    "    # not be considered as either a positive or negative edge.\n",
    "\n",
    "    neg_edge_list = []\n",
    "\n",
    "    ############# Your code here ############\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    pos_set = set(G.edges())\n",
    "    visited_set = set()\n",
    "\n",
    "    # G_new = random.shuffle([i for i in G.nodes()])\n",
    "    \n",
    "    for n_i in G.nodes():\n",
    "        for n_j in G.nodes():\n",
    "            if n_i == n_j or (n_i, n_j) in pos_set or (n_j, n_i) in pos_set or (n_i, n_j) in visited_set or (n_j, n_i) in visited_set:\n",
    "                continue\n",
    "            neg_edge_list.append((n_i, n_j))\n",
    "            visited_set.add((n_i, n_j))\n",
    "            visited_set.add((n_j, n_i))\n",
    "            if len(visited_set) == num_neg_samples:\n",
    "                break\n",
    "\n",
    "    return neg_edge_list\n",
    "\n",
    "# Sample 78 negative edges\n",
    "neg_edge_list = sample_negative_edges(G, len(pos_edge_list))\n",
    "\n",
    "# Transform the negative edge list to tensor\n",
    "neg_edge_index = edge_list_to_tensor(neg_edge_list)\n",
    "print(\"The neg_edge_index tensor has shape {}\".format(neg_edge_index.shape))\n",
    "\n",
    "# Which of following edges can be negative ones?\n",
    "edge_1 = (7, 1)\n",
    "edge_2 = (1, 33)\n",
    "edge_3 = (33, 22)\n",
    "edge_4 = (0, 4)\n",
    "edge_5 = (4, 2)\n",
    "\n",
    "############# Your code here ############\n",
    "## Note:\n",
    "## 1: For each of the 5 edges, print whether it can be negative edge\n",
    "\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830c68f2",
   "metadata": {
    "id": "830c68f2"
   },
   "source": [
    "## Training Node Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323ab4b5",
   "metadata": {
    "id": "323ab4b5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9ca17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ab9ca17",
    "outputId": "9c5c8fe8-d361-4306-8b66-8d42ca913357"
   },
   "outputs": [],
   "source": [
    "emb_sample = nn.Embedding(num_embeddings=4, embedding_dim=8)\n",
    "print('Sample embedding layer: {}'.format(emb_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e396adf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e396adf",
    "outputId": "05cbd093-8180-4b5a-8e1d-e633a510d119"
   },
   "outputs": [],
   "source": [
    "# Select an embedding in emb_sample\n",
    "id = torch.LongTensor([1])\n",
    "print(emb_sample(id))\n",
    "\n",
    "# Select multiple embeddings\n",
    "ids = torch.LongTensor([1, 3])\n",
    "print(emb_sample(ids))\n",
    "\n",
    "# Get the shape of the embedding weight matrix\n",
    "shape = emb_sample.weight.data.shape\n",
    "print(shape)\n",
    "\n",
    "# Overwrite the weight to tensor with all ones\n",
    "emb_sample.weight.data = torch.ones(shape)\n",
    "\n",
    "# Let's check if the emb is indeed initilized\n",
    "ids = torch.LongTensor([0, 3])\n",
    "print(emb_sample(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fbed24",
   "metadata": {
    "id": "e6fbed24"
   },
   "source": [
    "### Creating the Node Embedding Matrix  \n",
    "- We want to obtain a **16-dimensional** vector for each node in the Karate Club graph.  \n",
    "- We will initialize the matrix with a **uniform distribution** in the range \\([0, 1)\\). This can be done using [`torch.rand`](https://pytorch.org/docs/stable/generated/torch.rand.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291627e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "291627e4",
    "outputId": "32227b90-55f8-4368-a22e-46459bd19b5e"
   },
   "outputs": [],
   "source": [
    "# Please do not change / reset the random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def create_node_emb(num_node=34, embedding_dim=16):\n",
    "    # TODO: Implement this function that will create the node embedding matrix.\n",
    "    # A torch.nn.Embedding layer will be returned. You do not need to change \n",
    "    # the values of num_node and embedding_dim. The weight matrix of returned \n",
    "    # layer should be initialized under uniform distribution. \n",
    "\n",
    "    emb = torch.nn.Embedding(num_embeddings=num_node, embedding_dim=embedding_dim)\n",
    "\n",
    "    ############# Your code here ############\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    return emb\n",
    "\n",
    "emb = create_node_emb()\n",
    "ids = torch.LongTensor([0, 3])\n",
    "\n",
    "# Print the embedding layer\n",
    "print(\"Embedding: {}\".format(emb))\n",
    "\n",
    "# An example that gets the embeddings for node 0 and 3\n",
    "print(emb(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfbc66b",
   "metadata": {
    "id": "cbfbc66b"
   },
   "source": [
    "### Visualizing Embeddings Using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc88ce45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T12:09:02.577304Z",
     "start_time": "2022-09-15T12:09:02.569081Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "fc88ce45",
    "outputId": "2a52ecb0-6c6c-43d7-a4a6-642419c3d098"
   },
   "outputs": [],
   "source": [
    "def visualize_emb(emb):\n",
    "    X = emb.weight.data.numpy()\n",
    "    pca = PCA(n_components=2)\n",
    "    components = pca.fit_transform(X)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    club1_x = []\n",
    "    club1_y = []\n",
    "    club2_x = []\n",
    "    club2_y = []\n",
    "    for node in G.nodes(data=True):\n",
    "        if node[1]['club'] == 'Mr. Hi':\n",
    "            club1_x.append(components[node[0]][0])\n",
    "            club1_y.append(components[node[0]][1])\n",
    "        else:\n",
    "            club2_x.append(components[node[0]][0])\n",
    "            club2_y.append(components[node[0]][1])\n",
    "    plt.scatter(club1_x, club1_y, color=\"red\", label=\"Mr. Hi\")\n",
    "    plt.scatter(club2_x, club2_y, color=\"blue\", label=\"Officer\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_emb(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9714cd9",
   "metadata": {
    "id": "a9714cd9"
   },
   "source": [
    "### Now Let's Move on to Training  \n",
    "\n",
    "We want to optimize the embeddings for the task of classifying edges as positive or negative. By taking the edges and the embeddings for each node, the dot product of the embeddings, followed by a sigmoid function, should yield the probability of whether an edge is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17221e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "b17221e1",
    "outputId": "935f6488-6b36-4b3e-c111-caea89a048d8"
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "import torch.nn as nn\n",
    "\n",
    "def accuracy(pred, label):\n",
    "    # TODO: Implement the accuracy function. This function takes the \n",
    "    # pred tensor (the resulting tensor after sigmoid) and the label \n",
    "    # tensor (torch.LongTensor). Predicted value greater than 0.5 will \n",
    "    # be classified as label 1. Else it will be classified as label 0.\n",
    "    # The returned accuracy should be rounded to 4 decimal places. \n",
    "    # For example, accuracy 0.82956 will be rounded to 0.8296.\n",
    "\n",
    "    accu = 0.0\n",
    "\n",
    "    ############# Your code here ############\n",
    "\n",
    "    #########################################\n",
    "\n",
    "    accu = round(((torch.round(pred) == label).sum()/label.size(0)).item(), 4)\n",
    "\n",
    "    return accu\n",
    "\n",
    "def train(emb, loss_fn, sigmoid, train_label, train_edge):\n",
    "    # TODO: Train the embedding layer here. You can also change epochs and \n",
    "    # learning rate. In general, you need to implement: \n",
    "    # (1) Get the embeddings of the nodes in train_edge\n",
    "    # (2) Dot product the embeddings between each node pair\n",
    "    # (3) Feed the dot product result into sigmoid\n",
    "    # (4) Feed the sigmoid output into the loss_fn\n",
    "    # (5) Print both loss and accuracy of each epoch \n",
    "    # (6) Update the embeddings using the loss and optimizer \n",
    "    # (as a sanity check, the loss should decrease during training)\n",
    "\n",
    "    epochs = 500\n",
    "    learning_rate = 0.1\n",
    "\n",
    "    optimizer = SGD(emb.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "    for i in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        product = torch.sum(torch.mul(emb(train_edge[0]), emb(train_edge[1])), axis=1)\n",
    "        pred = torch.sigmoid(product)\n",
    "        loss = loss_fn(pred, train_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            acc = accuracy(pred, train_label)\n",
    "            if i % 100 == 0:\n",
    "                visualize_emb(emb)\n",
    "            print(loss.item(), acc)\n",
    "\n",
    "    ############# Your code here ############\n",
    "    \n",
    "#########################################\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "print(pos_edge_index.shape)\n",
    "\n",
    "# Generate the positive and negative labels\n",
    "pos_label = torch.ones(pos_edge_index.shape[1], )\n",
    "neg_label = torch.zeros(neg_edge_index.shape[1], )\n",
    "\n",
    "# Concat positive and negative labels into one tensor\n",
    "train_label = torch.cat([pos_label, neg_label], dim=0)\n",
    "\n",
    "# Concat positive and negative edges into one tensor\n",
    "# Since the network is very small, we do not split the edges into val/test sets\n",
    "train_edge = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
    "print(train_edge.shape)\n",
    "\n",
    "train(emb, loss_fn, sigmoid, train_label, train_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abc449d",
   "metadata": {
    "id": "0abc449d"
   },
   "source": [
    "### Now, Let's Visualize the Trained Embeddings  \n",
    "As we can see, the classes are now more clearly separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98472a56",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "98472a56",
    "outputId": "2fe8d2cc-8cd1-4b4a-f6cb-62f6174b6de9"
   },
   "outputs": [],
   "source": [
    "visualize_emb(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-vitamin",
   "metadata": {
    "id": "fatty-vitamin"
   },
   "source": [
    "## Approaches with Graph Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-prerequisite",
   "metadata": {
    "id": "human-prerequisite"
   },
   "source": [
    "### Counting Graphlets of a Given Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56fb2f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a56fb2f2",
    "outputId": "8d37e5e4-dc2e-4bc3-e24f-281fafa38b0f"
   },
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "g.add_edge(1,2);g.add_edge(1,3)\n",
    "g.add_edge(1,7);g.add_edge(2,4)\n",
    "g.add_edge(3,4);g.add_edge(3,5)\n",
    "g.add_edge(3,6);g.add_edge(4,5)\n",
    "g.add_edge(5,6);g.add_edge(6,7)\n",
    "\n",
    "import itertools\n",
    "\n",
    "target = nx.Graph()\n",
    "target.add_edge(1,2)\n",
    "target.add_edge(2,3)\n",
    "\n",
    "for sub_nodes in itertools.combinations(g.nodes(),len(target.nodes())):\n",
    "    subg = g.subgraph(sub_nodes)\n",
    "    if nx.is_connected(subg) and nx.is_isomorphic(subg, target):\n",
    "        print(subg.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-contributor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T12:14:41.094448Z",
     "start_time": "2022-09-15T12:14:41.091735Z"
    },
    "id": "sustained-contributor"
   },
   "source": [
    "### Now, Let's Train a Model on Graph Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-tunnel",
   "metadata": {
    "id": "fifty-tunnel"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-thanks",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T12:13:02.164078Z",
     "start_time": "2022-09-15T12:13:02.158583Z"
    },
    "id": "optical-thanks"
   },
   "outputs": [],
   "source": [
    "# Generate simple dataset\n",
    "def create_dataset():\n",
    "    Gs = [nx.cycle_graph(i) for i in range(3, 103)]\n",
    "    Gs.extend([nx.path_graph(i) for i in range(3, 103)])\n",
    "    y = [0 if i < 100 else 1 for i in range(200)]\n",
    "\n",
    "    return Gs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-crash",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T12:13:12.016951Z",
     "start_time": "2022-09-15T12:13:11.984105Z"
    },
    "id": "spoken-crash"
   },
   "outputs": [],
   "source": [
    "Gs, y = create_dataset()\n",
    "G_train, G_test, y_train, y_test = train_test_split(Gs, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2sSdKFTqilYj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "2sSdKFTqilYj",
    "outputId": "3f8bd392-f1ee-4ebe-a09c-bdca69f12bd1"
   },
   "outputs": [],
   "source": [
    "nx.draw(Gs[150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-preservation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T12:17:02.993758Z",
     "start_time": "2022-09-15T12:17:02.980753Z"
    },
    "id": "continuing-preservation"
   },
   "outputs": [],
   "source": [
    "# Compute the shortest path kernel\n",
    "def shortest_path_kernel(Gs_train, Gs_test):\n",
    "    all_paths = dict()\n",
    "    sp_counts_train = dict()\n",
    "\n",
    "    for i, G in enumerate(Gs_train):\n",
    "        sp_lengths = dict(nx.shortest_path_length(G))\n",
    "        sp_counts_train[i] = dict()\n",
    "        nodes = G.nodes()\n",
    "        for v1 in nodes:\n",
    "            for v2 in nodes:\n",
    "                if v2 in sp_lengths[v1]:\n",
    "                    length = sp_lengths[v1][v2]\n",
    "                    if length in sp_counts_train[i]:\n",
    "                        sp_counts_train[i][length] += 1\n",
    "                    else:\n",
    "                        sp_counts_train[i][length] = 1\n",
    "\n",
    "                    if length not in all_paths:\n",
    "                        all_paths[length] = len(all_paths)\n",
    "\n",
    "    sp_counts_test = dict()\n",
    "\n",
    "    for i, G in enumerate(Gs_test):\n",
    "        sp_lengths = dict(nx.shortest_path_length(G))\n",
    "        sp_counts_test[i] = dict()\n",
    "        nodes = G.nodes()\n",
    "        for v1 in nodes:\n",
    "            for v2 in nodes:\n",
    "                if v2 in sp_lengths[v1]:\n",
    "                    length = sp_lengths[v1][v2]\n",
    "                    if length in sp_counts_test[i]:\n",
    "                        sp_counts_test[i][length] += 1\n",
    "                    else:\n",
    "                        sp_counts_test[i][length] = 1\n",
    "\n",
    "                    if length not in all_paths:\n",
    "                        all_paths[length] = len(all_paths)\n",
    "\n",
    "    phi_train = np.zeros((len(G_train), len(all_paths)))\n",
    "    for i in range(len(G_train)):\n",
    "        for length in sp_counts_train[i]:\n",
    "            phi_train[i, all_paths[length]] = sp_counts_train[i][length]\n",
    "\n",
    "    phi_test = np.zeros((len(Gs_test), len(all_paths)))\n",
    "    for i in range(len(Gs_test)):\n",
    "        for length in sp_counts_test[i]:\n",
    "            phi_test[i, all_paths[length]] = sp_counts_test[i][length]\n",
    "\n",
    "    K_train = np.dot(phi_train, phi_train.T)\n",
    "    K_test = np.dot(phi_test, phi_train.T)\n",
    "\n",
    "    return K_train, K_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-truth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T12:17:03.187382Z",
     "start_time": "2022-09-15T12:17:03.176574Z"
    },
    "id": "optional-truth"
   },
   "outputs": [],
   "source": [
    "# Compute the graphlet kernel\n",
    "def graphlet_kernel(Gs_train, Gs_test, n_samples=200):\n",
    "    graphlets = [nx.Graph(), nx.Graph(), nx.Graph(), nx.Graph()]\n",
    "\n",
    "    graphlets[0].add_nodes_from(range(3))\n",
    "\n",
    "    graphlets[1].add_nodes_from(range(3))\n",
    "    graphlets[1].add_edge(0, 1)\n",
    "\n",
    "    graphlets[2].add_nodes_from(range(3))\n",
    "    graphlets[2].add_edge(0, 1)\n",
    "    graphlets[2].add_edge(1, 2)\n",
    "\n",
    "    graphlets[3].add_nodes_from(range(3))\n",
    "    graphlets[3].add_edge(0, 1)\n",
    "    graphlets[3].add_edge(1, 2)\n",
    "    graphlets[3].add_edge(0, 2)\n",
    "\n",
    "    phi_train = np.zeros((len(G_train), 4))\n",
    "\n",
    "    for i, graph in enumerate(Gs_train):\n",
    "        for j in range(n_samples):\n",
    "            rnd_set = np.random.choice(graph.nodes(), 3)\n",
    "            sub_g = graph.subgraph(rnd_set)\n",
    "            phi_train[i] += np.array([nx.is_isomorphic(g, sub_g) for g in graphlets])\n",
    "\n",
    "    phi_test = np.zeros((len(G_test), 4))\n",
    "\n",
    "    for i, graph in enumerate(Gs_test):\n",
    "        for j in range(n_samples):\n",
    "            rnd_set = np.random.choice(graph.nodes(), 3)\n",
    "            sub_g = graph.subgraph(rnd_set)\n",
    "            phi_test[i] += np.array([nx.is_isomorphic(g, sub_g) for g in graphlets])\n",
    "\n",
    "\n",
    "    K_train = np.dot(phi_train, phi_train.T)\n",
    "    K_test = np.dot(phi_test, phi_train.T)\n",
    "\n",
    "    return K_train, K_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-figure",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-15T12:24:56.139456Z",
     "start_time": "2022-09-15T12:24:42.697734Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "official-figure",
    "outputId": "c811c88e-18ca-4e31-9591-68003deb64c2"
   },
   "outputs": [],
   "source": [
    "K_train_sp, K_test_sp = shortest_path_kernel(G_train, G_test)\n",
    "\n",
    "K_train_gk, K_test_gk = graphlet_kernel(G_train, G_test, 500)\n",
    "\n",
    "model = SVC(kernel='precomputed')\n",
    "print(\"Starting Training for the Graphlet\")\n",
    "model.fit(K_train_gk, y_train)\n",
    "y_pred = model.predict(K_test_gk)\n",
    "print(\"Accuracy for Graphlet\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "model = SVC(kernel='precomputed')\n",
    "print(\"Starting Training for the Shortest Path\")\n",
    "model.fit(K_train_sp, y_train)\n",
    "y_pred = model.predict(K_test_sp)\n",
    "print(\"Accuracy for Shortest Path\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IP7-MgjNknjM",
   "metadata": {
    "id": "IP7-MgjNknjM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
